import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TextClassificationPipeline
import torch
import numpy as np

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="RoBERTa Sentiment", page_icon="ğŸ¤–", layout="wide")
st.markdown("<h1 style='text-align: center; color: #6A5ACD;'>ğŸ” Application d'Analyse des Sentiments RoBERTa ğŸ”</h1>", unsafe_allow_html=True)
st.markdown("<h4 style='text-align: center; color: grey;'>Analyse des sentiments (Positif, Neutre, NÃ©gatif) avec le modÃ¨le RoBERTa</h4>", unsafe_allow_html=True)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ùˆ Tokenizer
@st.cache_resource
def load_roberta():
    model_name = "cardiffnlp/twitter-roberta-base-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_roberta()

# Ø¥Ù†Ø´Ø§Ø¡ pipeline ÙŠØ¯ÙˆÙŠ
def analyze_sentiment(text):
    encoded_input = tokenizer(text, return_tensors='pt', truncation=True)
    with torch.no_grad():
        output = model(**encoded_input)
    scores = torch.nn.functional.softmax(output.logits, dim=1).numpy()[0]
    labels = ['NÃ©gatif ğŸ˜', 'Neutre ğŸ˜', 'Positif ğŸ˜€']
    max_idx = np.argmax(scores)
    return labels[max_idx], scores[max_idx]

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
text = st.text_area("ğŸ“ Entrez un texte Ã  analyser", height=150)

if st.button("ğŸ” Analyser"):
    if text.strip() != "":
        with st.spinner("Analyse en cours..."):
            label, score = analyze_sentiment(text)
            st.markdown(f"### âœ… RÃ©sultat : **{label}**")
            st.markdown(f"### ğŸ”¢ Score : `{score*100:.2f}%`")
    else:
        st.warning("â— Veuillez entrer un texte d'abord.")
