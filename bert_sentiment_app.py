import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ùˆ Tokenizer Ù…Ø¹ Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
@st.cache_resource
def load_model():
    model_name = "cardiffnlp/twitter-roberta-base-sentiment"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(model_name)

    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø¬Ù‡Ø§Ø² CPU Ø¨Ø´ÙƒÙ„ ØµØ±ÙŠØ­
    device = torch.device("cpu")  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù„Ø¯ÙŠÙƒ GPUØŒ ÙŠÙ…ÙƒÙ† ØªØºÙŠÙŠØ±Ù‡Ø§ Ø¥Ù„Ù‰ "cuda"
    
    # Ù†Ù‚Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù‡Ø§Ø² Ø§Ù„Ù…Ø­Ø¯Ø¯
    model.to(device)

    # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ Ø§Ù„Ø£Ù†Ø§Ø¨ÙŠØ¨
    return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer, device=-1)  # device=-1 ÙŠØ¹Ù†ÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU

# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ
def analyze_sentiment(text):
    classifier = load_model()
    result = classifier(text)[0]
    label_map = {
        'LABEL_0': 'Ø³Ù„Ø¨ÙŠ ğŸ˜ ',
        'LABEL_1': 'Ù…Ø­Ø§ÙŠØ¯ ğŸ˜',
        'LABEL_2': 'Ø¥ÙŠØ¬Ø§Ø¨ÙŠ ğŸ˜Š'
    }
    sentiment = label_map[result['label']]
    score = round(result['score'] * 100, 2)
    return sentiment, score

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.set_page_config(page_title="ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± - RoBERTa", layout="centered")
st.title("ğŸ¤– RoBERTa Sentiment Analysis App")
st.write("Analyse des sentiments (Positif, Neutre, NÃ©gatif) avec le modÃ¨le RoBERTa")

text_input = st.text_area("ğŸ“ Entrez un texte Ã  analyser", "")

if st.button("Analyser"):
    if text_input.strip():
        with st.spinner("Analyse en cours..."):
            sentiment, score = analyze_sentiment(text_input)
            st.success(f"**RÃ©sultat** : {sentiment} (confiance : {score}%)")
    else:
        st.warning("Veuillez entrer un texte.")
